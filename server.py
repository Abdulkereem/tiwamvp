import asyncio\nimport uuid\nimport re\nfrom fastapi import FastAPI, WebSocket, WebSocketDisconnect\nfrom fastapi.responses import FileResponse\nfrom typing import Dict\n\n# Import from our modules\nfrom chat_memory import create_chat_session, add_message_to_session, get_formatted_history\nfrom models import call_gpt, call_deepseek\nfrom consensus import verify_and_merge\nfrom tools import tavily_web_search, scrape_url # New tools imported\n\napp = FastAPI()\n\n# --- Core Identity & Business Logic ---\n\nTIWA_PERSONA = (\n    \"I am TIWA (Task Intelligent Web Agent), a multi-model AI assistant created by Hive Innovation Lab. \"\n    \"My purpose is to provide accurate and helpful responses by orchestrating the strengths of several advanced AI models and accessing live web data. \"\n    \"Hive Innovation Lab was co-founded by Abdulkereem O Kereem and Akinola Solmipe, and I was engineered by Abdulkereem.\"\n)\n\nIDENTITY_TRIGGERS = [\"who are you\", \"what is tiwa\", \"what are you\", \"tell me about tiwa\", \"your name\"]\n\ndef is_identity_question(prompt: str) -> bool:\n    \"\"\"Check if the user\'s prompt is a direct question about TIWA\'s identity.\"\"\"\n    normalized_prompt = prompt.lower().strip()\n    return any(re.search(r\"\\b\" + re.escape(trigger) + r\"\\b\", normalized_prompt) for trigger in IDENTITY_TRIGGERS)\n\ndef generate_topic(prompt: str) -> str:\n    \"\"\"Generates a short topic from the user\'s prompt for the thinking indicator.\"\"\"\n    words = prompt.split()\n    topic = \" \".join(words[:5])\n    if len(words) > 5:\n        topic += \"...\"\n    return topic\n\nasync def process_single_prompt(websocket: WebSocket, chat_id: str, prompt: str, prompt_id: str):\n    \"\"\"Handles prompts by checking for identity, then tools, then multi-model consensus.\"\"\"\n    try:\n        # Step 1: Identity Check (Highest Priority)\n        if is_identity_question(prompt):\n            print(f\"Prompt ID {prompt_id}: Identity question. Responding directly.\", flush=True)\n            add_message_to_session(chat_id, \"user\", prompt)\n            add_message_to_session(chat_id, \"assistant\", TIWA_PERSONA, reasoning=\"Direct identity response\")\n            await websocket.send_json({\"type\": \"final\", \"prompt_id\": prompt_id, \"final_source\": TIWA_PERSONA})\n            return\n\n        # Add user message to history early for context\n        add_message_to_session(chat_id, \"user\", prompt)\n        topic = generate_topic(prompt)\n        await websocket.send_json({\"type\": \"thinking\", \"topic\": topic, \"prompt_id\": prompt_id})\n\n        # Step 2: Tool Use Check (Second Priority)\n        search_match = re.match(r\"^(?:search for|web search|look up|tavily search)\\s+(.+)\", prompt, re.IGNORECASE)\n        scrape_match = re.match(r\"^(?:read|scrape|get content of)\\s+(https?://[^\s]+)\", prompt, re.IGNORECASE)\n        \n        tool_result = None\n        tool_used = None\n\n        if search_match:\n            query = search_match.group(1)\n            print(f\"Prompt ID {prompt_id}: Identified as search command. Query: \'{query}\'\", flush=True)\n            tool_used, tool_result = \"Web Search\", await tavily_web_search(query)\n        elif scrape_match:\n            url = scrape_match.group(1)\n            print(f\"Prompt ID {prompt_id}: Identified as scrape command. URL: {url}\", flush=True)\n            tool_used, tool_result = \"URL Scraper\", await scrape_url(url)\n\n        if tool_result:\n            print(f\"Prompt ID {prompt_id}: Tool \'{tool_used}\' executed.\", flush=True)\n            add_message_to_session(chat_id, \"assistant\", tool_result, reasoning=f\"Direct result from {tool_used}\")\n            await websocket.send_json({\"type\": \"final\", \"prompt_id\": prompt_id, \"final_source\": tool_result})\n            return\n\n        # Step 3: Multi-Model Consensus (Default Flow)\n        history = get_formatted_history(chat_id)\n        contextual_prompt = f\"{history}\\nUser\'s current question: {prompt}\"\n\n        gpt_task = asyncio.create_task(call_gpt(contextual_prompt))\n        deepseek_task = asyncio.create_task(call_deepseek(contextual_prompt))\n        gpt_result, deepseek_result = await asyncio.gather(gpt_task, deepseek_task)\n\n        model_outputs = {\"gpt\": gpt_result, \"deepseek\": deepseek_result}\n        final_data = await verify_and_merge(outputs=model_outputs, evidence=[deepseek_result], prompt=contextual_prompt)\n\n        add_message_to_session(chat_id, \"assistant\", final_data[\'final_output\'], reasoning=f\"Final output after {final_data.get(\'consensus_method\')}\")\n        await websocket.send_json({\"type\": \"final\", \"prompt_id\": prompt_id, \"final_source\": final_data[\'final_output\']})\n\n    except Exception as e:\n        print(f\"Error processing prompt_id {prompt_id}: {e}\", flush=True)\n        await websocket.send_json({\"type\": \"error\", \"prompt_id\": prompt_id, \"message\": \"An error occurred.\"})\n\n@app.get(\"/\")\nasync def get():\n    return FileResponse(\'index.html\')\n\n@app.websocket(\"/ws/{client_id}\")\nasync def websocket_endpoint(websocket: WebSocket, client_id: str):\n    await websocket.accept()\n    chat_id = str(uuid.uuid4())\n    create_chat_session(chat_id)\n    \n    try:\n        while True:\n            data = await websocket.receive_json()\n            if data.get(\"action\") == \"message\":\n                prompt, prompt_id = data.get(\"prompt\"), data.get(\"prompt_id\")\n                if prompt and prompt_id:\n                    asyncio.create_task(process_single_prompt(websocket, chat_id, prompt, prompt_id))\n    except WebSocketDisconnect:\n        print(f\"Client {client_id} disconnected.\")\n    except Exception as e:\n        print(f\"Websocket error for client {client_id}: {e}\", flush=True)\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=3000)\n